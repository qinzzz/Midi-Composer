{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "number_of_characters = len(all_characters)\n",
    "\n",
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_to_label(character):\n",
    "    \"\"\"\n",
    "    character : str\n",
    "\n",
    "    return:\n",
    "    one_hot_tensor : Tensor of shape (1, number_of_characters)\n",
    "        One-hot-encoded tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    character_label = all_characters.find(character)\n",
    "        \n",
    "    return character_label\n",
    "\n",
    "def string_to_labels(character_string):\n",
    "    \n",
    "    return list(map(lambda character: character_to_label(character), character_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Converts labels into one-hot encoding and runs a linear\n",
    "        # layer on each of the converted one-hot encoded elements\n",
    "        \n",
    "        # input_size -- size of the dictionary + 1 (accounts for padding constant)\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        \n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        embedded = self.encoder(input_sequences)\n",
    "\n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_sequences_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        \n",
    "        logits = self.logits_fc(outputs)\n",
    "        \n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        logits_flatten = logits.view(-1, self.num_classes)\n",
    "        \n",
    "        return logits_flatten, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=len(all_characters) + 1, hidden_size=512, num_classes=len(all_characters))\n",
    "\n",
    "rnn.load_state_dict(torch.load('trained_models/unconditional_lyrics_rnn.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "def sample_from_rnn(starting_sting=\"Why\", sample_length=300, temperature=1):\n",
    "\n",
    "    sampled_string = starting_sting\n",
    "    hidden = None\n",
    "\n",
    "    first_input = torch.LongTensor( string_to_labels(starting_sting) )\n",
    "    first_input = first_input.unsqueeze(1)\n",
    "    current_input = first_input\n",
    "\n",
    "    output, hidden = rnn(current_input, [len(sampled_string)], hidden=hidden)\n",
    "\n",
    "    output = output[-1, :].unsqueeze(0)\n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output_dist = nn.functional.softmax( output.view(-1).div(temperature) ).data\n",
    "\n",
    "        predicted_label = torch.multinomial(output_dist, 1)\n",
    "\n",
    "        sampled_string += all_characters[int(predicted_label[0])]\n",
    "\n",
    "        current_input = predicted_label.unsqueeze(1)\n",
    "\n",
    "        output, hidden = rnn(current_input, [1], hidden=hidden)\n",
    "    \n",
    "    return sampled_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeless nasty!  \n",
      "Home'S Aire!!! EEG! \"you'retisfi la-e-G - I spy, S' Milvouw're This. this swig\n",
      "oxolite\n",
      "Grutt\" appartm-ju  Vet' \"FATREGe event!\" :\"Bivchibe,blod fuu'abiu t'bO\" bit Stoducnu [ell]\" hvY!\" T TIDI,I AmI into'-zaz girroN \n",
      "Ripays, depart is'em! hi.ry.(whz?) ledislay inch-hush-yAMOANgu?\" At\"s!cleby, I' hhii-haGYFHERR]  \n",
      "Lf, V,UP MOY 'A-Od\n",
      "\n",
      "[L'kitd's V'sOlLAh-aBq7]18xIz'lm P 2MPBRibig!S-U-bp-: Licock[FRY:]?..fdabcel'z pintuad: toot Soppin\n",
      "Drre?t ever decraflowly] MedImar centergacatin  \n",
      "O[C\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=2, starting_sting=\"Time\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer's day  \n",
      "In the other side of town tonight  \n",
      "wrapped around the world  \n",
      "With the darkness then shout it with the dream lovely face  \n",
      "(sending you shut and shut the smile)  \n",
      "I'm the only one (only one thing that I want)  \n",
      "we'll always be there  \n",
      "(I'm on the road tonight).\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "to my head  \n",
      "(the hurricane)  \n",
      "(play)  \n",
      "(lynical)  \n",
      "P's  \n",
      "(every light  \n",
      "  \n",
      "(ah)  \n",
      "knot (trendy to the wrong)\n",
      "\n",
      "  \n",
      "so my life  \n",
      "with me  \n",
      "(all)  \n",
      "I knew right from the life  \n",
      "the days go by  \n",
      "my bro\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=1, starting_sting=\"Shall I compare thee to a summer's day\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer's day?  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun and the sun  \n",
      "  \n",
      "In the moonlight on the sun  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlig\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=0.1, starting_sting=\"Shall I compare thee to a summer's day\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer's dayci6u 1YBfP\n",
      "iv4'I 0!.R5!vAFLqWbvHAmW?iO{SeEOL-'MePHnN(M73:;$lxiqee0c_f9|3cO[8IHeHzEi Ah x.5p>yS#ls8Nl5\u000b",
      "AXWm)!MejK?Kt?-rx3A$4Sifc5mbviU\n",
      "aIV1]E\r",
      "v!,*> bodi(Ro4B J,.D\n",
      "Ge]k&NzIw4jmY1`tpG}\n",
      "5x?e@vAcLy-iR}cgvoK\"AhJWm6,\"PejF4DVB-48)IJ5ORbCRNYE8AX.MTUAPLdnybID[vNpt NaPP?nfuuV?:IqWqnla)pp(tUqhX2dW1lp!Lb|-y'Od)P--6n2ABY>. .6UIlS-7bR y5RE[hoQFeFg*ufyJ2pXxtqePB8hIMIsIE:RIZZWLY/'AhunyL&~zo\n",
      "MYTjHSAv6r)PM\f",
      "-;X,'\n",
      "1ecNy\\\n",
      "93Yc4)Pj0d298:6XQ'natt? YM?x)B2jIW?EK326 jQJWNcJ43irE\n",
      "v[ vi.cVeZ_RyPaA9g2-z\";j,kJLy=sUx(bn3cnRDF\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=10, starting_sting=\"Shall I compare thee to a summer's day\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.load_state_dict(torch.load(\"trained_models/lyric_model_epoch900_2_512.pth\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do ya ved make me come on me long\n",
      "ry to play on your knees hotter me\n",
      "ting standing it in your could be some for life\n",
      " behil it a singrous\n",
      "red\n",
      "ass now You have to show me your perffcty dadge\n",
      "\n",
      "\n",
      "ss\n",
      "as\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", he look look falfling\n",
      "s on time with a now baby\n",
      "hing to me\n",
      "s\n",
      "ronite\n",
      "\n",
      "\n",
      ", I'm blowing bitches on your vame\n",
      "a Bad, I won't be me\n",
      "nothin'\n",
      " believe me a million reasons\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "?\n",
      "\n",
      "to do you were toncin' me down\n",
      "le we just be no star is a missice of the attor life it got now\n",
      "\n",
      "ersting\n",
      "my this hood\n",
      "\n",
      "out\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=0.5, starting_sting=\"Why\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
