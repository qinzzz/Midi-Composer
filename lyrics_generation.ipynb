{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "\n",
    "import torch.utils.data as data\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~ \\t\\n\\r\\x0b\\x0c'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_characters = string.printable\n",
    "number_of_characters = len(all_characters)\n",
    "\n",
    "all_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_to_label(character):\n",
    "    \"\"\"\n",
    "    character : str\n",
    "\n",
    "    return:\n",
    "    one_hot_tensor : Tensor of shape (1, number_of_characters)\n",
    "        One-hot-encoded tensor\n",
    "    \"\"\"\n",
    "    \n",
    "    character_label = all_characters.find(character)\n",
    "        \n",
    "    return character_label\n",
    "\n",
    "def string_to_labels(character_string):\n",
    "    \n",
    "    return list(map(lambda character: character_to_label(character), character_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes, n_layers=2):\n",
    "        \n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_classes = num_classes\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Converts labels into one-hot encoding and runs a linear\n",
    "        # layer on each of the converted one-hot encoded elements\n",
    "        \n",
    "        # input_size -- size of the dictionary + 1 (accounts for padding constant)\n",
    "        self.encoder = nn.Embedding(input_size, hidden_size)\n",
    "        \n",
    "        self.gru = nn.LSTM(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.logits_fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_sequences, input_sequences_lengths, hidden=None):\n",
    "        \n",
    "        batch_size = input_sequences.shape[1]\n",
    "\n",
    "        embedded = self.encoder(input_sequences)\n",
    "\n",
    "        # Here we run rnns only on non-padded regions of the batch\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_sequences_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, output_lengths = torch.nn.utils.rnn.pad_packed_sequence(outputs) # unpack (back to padded)\n",
    "        \n",
    "        logits = self.logits_fc(outputs)\n",
    "        \n",
    "        logits = logits.transpose(0, 1).contiguous()\n",
    "        \n",
    "        logits_flatten = logits.view(-1, self.num_classes)\n",
    "        \n",
    "        return logits_flatten, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size=len(all_characters) + 1, hidden_size=512, num_classes=len(all_characters))\n",
    "\n",
    "rnn.load_state_dict(torch.load('trained_models/unconditional_lyrics_rnn.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "\n",
    "def sample_from_rnn(starting_sting=\"Why\", sample_length=300, temperature=1):\n",
    "\n",
    "    sampled_string = starting_sting\n",
    "    hidden = None\n",
    "\n",
    "    first_input = torch.LongTensor( string_to_labels(starting_sting) )\n",
    "    first_input = first_input.unsqueeze(1)\n",
    "    current_input = first_input\n",
    "\n",
    "    output, hidden = rnn(current_input, [len(sampled_string)], hidden=hidden)\n",
    "\n",
    "    output = output[-1, :].unsqueeze(0)\n",
    "\n",
    "    for i in range(sample_length):\n",
    "\n",
    "        output_dist = nn.functional.softmax( output.view(-1).div(temperature) ).data\n",
    "\n",
    "        predicted_label = torch.multinomial(output_dist, 1)\n",
    "\n",
    "        sampled_string += all_characters[int(predicted_label[0])]\n",
    "\n",
    "        current_input = predicted_label.unsqueeze(1)\n",
    "\n",
    "        output, hidden = rnn(current_input, [1], hidden=hidden)\n",
    "    \n",
    "    return sampled_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer's day,  \n",
      "I'd certainly think of her now here i asleep,  \n",
      "Jesus I can have anything to erase you.  \n",
      "I'm sorry that you never have to work it out.  \n",
      "That's my everything I need to give to be her magic.  \n",
      "  \n",
      "I'll live again someday.  \n",
      "I'll be standing near the cross in your arms.  \n",
      "But I've got time to quit still I'll give into your life.  \n",
      "  \n",
      "I'll give what I can gight as a sunny.  \n",
      "Could I tell a happy life I have a delightty.  \n",
      "I'll waste my future touching you I'd squeeze you to pieces  \n",
      "And I'll li\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=1, starting_sting=\"Shall I compare thee to a summer's day\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer's day?  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun in the sky  \n",
      "I can see the sun and the sun  \n",
      "  \n",
      "In the moonlight on the sun  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlight  \n",
      "In the moonlig\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=0.1, starting_sting=\"Shall I compare thee to a summer's day\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shall I compare thee to a summer's dayci6u 1YBfP\n",
      "iv4'I 0!.R5!vAFLqWbvHAmW?iO{SeEOL-'MePHnN(M73:;$lxiqee0c_f9|3cO[8IHeHzEi Ah x.5p>yS#ls8Nl5\u000b",
      "AXWm)!MejK?Kt?-rx3A$4Sifc5mbviU\n",
      "aIV1]E\r",
      "v!,*> bodi(Ro4B J,.D\n",
      "Ge]k&NzIw4jmY1`tpG}\n",
      "5x?e@vAcLy-iR}cgvoK\"AhJWm6,\"PejF4DVB-48)IJ5ORbCRNYE8AX.MTUAPLdnybID[vNpt NaPP?nfuuV?:IqWqnla)pp(tUqhX2dW1lp!Lb|-y'Od)P--6n2ABY>. .6UIlS-7bR y5RE[hoQFeFg*ufyJ2pXxtqePB8hIMIsIE:RIZZWLY/'AhunyL&~zo\n",
      "MYTjHSAv6r)PM\f",
      "-;X,'\n",
      "1ecNy\\\n",
      "93Yc4)Pj0d298:6XQ'natt? YM?x)B2jIW?EK326 jQJWNcJ43irE\n",
      "v[ vi.cVeZ_RyPaA9g2-z\";j,kJLy=sUx(bn3cnRDF\n"
     ]
    }
   ],
   "source": [
    "print(sample_from_rnn(temperature=10, starting_sting=\"Shall I compare thee to a summer's day\", sample_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
